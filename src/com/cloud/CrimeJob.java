package com.cloud;

import java.io.File;
import java.io.IOException;

import org.apache.commons.io.FileUtils;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class CrimeJob {

	public static void main(String[] args) throws Exception{
		// TODO Auto-generated method stub
		//////////////////////////////////////////////
		///////////////////////////////////
		//File directory = new File(args[1]);

		//try {
		//	delete(directory);
		//} catch (IOException e) {
		//	e.printStackTrace();
		//}
		//////////
		FileUtils.deleteDirectory(new File("D:/Cloud/input/data/output"));
		/////////////////////////////////////////////////

		Job job = new Job();

		/* Autogenerated initialization. */
		initJob(job);

		/* Custom initialization. */
		initCustom(job);

		/* Tell Task Tracker this is the main */
		job.setJarByClass(CrimeJob.class);

		/* This is an example of how to set input and output. */
		FileInputFormat.setInputPaths(job, args[0]);
		FileOutputFormat.setOutputPath(job, new Path(args[1]));

		/* You can now do any other job customization. */
		// job.setXxx(...);

		/* And finally, we submit the job. */
		job.submit();

		job.waitForCompletion(true);
	}

	
    // delete folder function
    ///
    public static void delete(File file)
        	throws IOException{

        	if(file.isDirectory()){

        		//directory is empty, then delete it
        		if(file.list().length==0){

        		   file.delete();
        		   System.out.println("Directory is deleted : "
                                                     + file.getAbsolutePath());

        		}else{

        		   //list all the directory contents
            	   String files[] = file.list();

            	   for (String temp : files) {
            	      //construct the file structure
            	      File fileDelete = new File(file, temp);

            	      //recursive delete
            	     delete(fileDelete);
            	   }

            	   //check the directory again, if empty then delete it
            	   if(file.list().length==0){
               	     file.delete();
            	     System.out.println("Directory is deleted : "
                                                      + file.getAbsolutePath());
            	   }
        		}

        	}else{
        		//if file, then delete it
        		file.delete();
        		System.out.println("File is deleted : " + file.getAbsolutePath());
        	}
        }
     
    
    //
    /**
     * This method is executed by the workflow
     */
    public static void initCustom(Job job) {
        // Add custom initialisation here, you may have to rebuild your project before
        // changes are reflected in the workflow.
    }

    /** This method is called from within the constructor to
     * initialize the job.
     * WARNING: Do NOT modify this code. The content of this method is
     * always regenerated by the Job Editor.
     */
    @SuppressWarnings("unchecked")
    // <editor-fold defaultstate="collapsed" desc="Generated Code">//GEN-BEGIN:initJob
    public static void initJob(Job job) {
org.apache.hadoop.conf.Configuration conf = job.getConfiguration();
// Generating code using Karmasphere Protocol for Hadoop 0.20
// CG_GLOBAL

// CG_INPUT_HIDDEN
job.setInputFormatClass(org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat.class);

// CG_MAPPER_HIDDEN
job.setMapperClass(com.cloud.CrimeMapper.class);
job.getConfiguration().set("mapred.mapper.new-api", "true");

// CG_MAPPER
job.getConfiguration().set("mapred.map.tasks", "3");
job.setMapOutputKeyClass(org.apache.hadoop.io.Text.class);
job.setMapOutputValueClass(org.apache.hadoop.io.LongWritable.class);

// CG_PARTITIONER_HIDDEN
job.setPartitionerClass(org.apache.hadoop.mapreduce.lib.partition.HashPartitioner.class);

// CG_PARTITIONER

// CG_COMPARATOR_HIDDEN

// CG_COMPARATOR

// CG_COMBINER_HIDDEN

// CG_REDUCER_HIDDEN
job.setReducerClass(com.cloud.CrimeReducer.class);
job.getConfiguration().set("mapred.reducer.new-api", "true");

// CG_REDUCER
job.getConfiguration().set("mapred.reduce.tasks", "2");
job.setOutputKeyClass(org.apache.hadoop.io.Text.class);
job.setOutputValueClass(org.apache.hadoop.io.Text.class);

// CG_OUTPUT_HIDDEN
job.setOutputFormatClass(org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.class);

// CG_OUTPUT

// Others
job.getConfiguration().set("", "");
}
    
}
